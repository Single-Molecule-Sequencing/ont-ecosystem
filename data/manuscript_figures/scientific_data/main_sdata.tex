\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{lineno}
\usepackage{setspace}
\usepackage{xcolor}

% Line numbers for review
\linenumbers
\onehalfspacing

% Scientific Data style - no colons in title, max 110 chars
\title{A Registry Framework for Oxford Nanopore Sequencing Experiment Metadata and Quality Tracking}

\author{
[Author One]$^{1,*}$, [Author Two]$^{1}$, [Author Three]$^{2}$ \\
\\
\small $^{1}$Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI, USA \\
\small $^{2}$Department of Human Genetics, University of Michigan, Ann Arbor, MI, USA \\
\\
\small $^{*}$Corresponding author: [email]@umich.edu
}

\date{}

\begin{document}

\maketitle

% ============================================================================
% ABSTRACT (max 170 words for Scientific Data)
% ============================================================================
\begin{abstract}
Long-read nanopore sequencing has transformed genomics research, yet standardized metadata management remains challenging. We present a comprehensive registry of 165 Oxford Nanopore sequencing experiments conducted at the University of Michigan between August 2020 and December 2025. The registry captures experimental metadata including sample information, chemistry versions, basecalling parameters, device specifications, and quality control metrics with 100\% completeness for critical fields. The dataset documents the institutional transition from R10.4 to R10.4.1 chemistry (95.2\% adoption) and from Guppy to Dorado basecallers (82.4\% adoption). Quality metrics reveal median Q-scores of 14.0 and N50 values of 4,828 base pairs across diverse applications including plasmid sequencing (48.5\%), research projects (23.6\%), human genomics (9.7\%), and pharmacogenomics studies (7.9\%). The registry is provided in YAML, JSON, and CSV formats with event-sourced provenance tracking. This resource enables reproducible research, cross-study comparisons, and serves as a reference for institutional nanopore sequencing practices.
\end{abstract}

\clearpage

% ============================================================================
% BACKGROUND & SUMMARY
% ============================================================================
\section*{Background \& Summary}

Long-read sequencing technologies have fundamentally transformed genomic research by enabling the resolution of complex structural variants, repetitive regions, and full-length transcript isoforms that remain inaccessible to short-read platforms\cite{logsdon2020long}. Oxford Nanopore Technologies (ONT) has emerged as a leading platform, offering real-time sequencing with reads spanning tens to hundreds of kilobases on devices ranging from the portable MinION to the high-throughput PromethION\cite{jain2016oxford}.

The rapid adoption of nanopore sequencing has created significant challenges for metadata management and experimental reproducibility. Unlike established short-read platforms with mature data management ecosystems, nanopore sequencing generates diverse metadata across multiple sources: run reports, sequencing summaries, basecalling logs, and quality control outputs. This fragmentation complicates cross-study comparisons and hinders the development of standardized quality benchmarks.

Clinical applications, particularly pharmacogenomics, demand rigorous provenance tracking to meet regulatory requirements\cite{relling2015pharmacogenomics}. The FAIR principles (Findable, Accessible, Interoperable, Reusable) provide a framework for scientific data management\cite{wilkinson2016fair}, yet practical implementations for nanopore sequencing metadata remain limited.

We present a comprehensive registry of 165 Oxford Nanopore sequencing experiments conducted at the University of Michigan, representing five years of institutional nanopore sequencing across diverse applications. The registry achieves 100\% metadata completeness through systematic extraction from primary data sources, pattern-based inference, and manual validation. This dataset documents technological transitions in chemistry and basecalling software, establishes quality control benchmarks, and provides a template for institutional metadata standardization.

% ============================================================================
% METHODS
% ============================================================================
\section*{Methods}

\subsection*{Data Sources}

Experiments were identified from three primary sources: (1) the institutional high-performance computing cluster (Great Lakes) containing archived sequencing runs, (2) local laboratory storage systems with active experiments, and (3) the ONT Open Data repository for public reference datasets. Source paths were recorded for provenance tracking.

\subsection*{Metadata Extraction}

Metadata extraction followed a hierarchical approach prioritizing authoritative sources:

\begin{enumerate}
    \item \textbf{Sequencing summaries} (\texttt{final\_summary.txt}, \texttt{sequencing\_summary*.txt}): Run identifiers, timestamps, yield statistics, and quality metrics
    \item \textbf{BAM headers}: Basecaller version, model parameters, and read group information extracted using samtools
    \item \textbf{POD5/Fast5 metadata}: Raw signal metadata including device identifiers, flowcell types, and run configuration via pod5 and ont\_fast5\_api libraries
    \item \textbf{Basecalling logs}: Model versions, GPU allocation, and processing parameters from dorado and guppy outputs
\end{enumerate}

\subsection*{Schema Design}

The registry schema captures metadata across six categories:

\begin{itemize}
    \item \textbf{Experiment}: Unique identifier, name, date, status
    \item \textbf{Sample}: Category, name, clinical identifier (where applicable)
    \item \textbf{Chemistry}: Flowcell type, library kit, chemistry version
    \item \textbf{Basecalling}: Software, version, model type, model version
    \item \textbf{Device}: Device type, position identifier
    \item \textbf{QC Metrics}: Total reads, bases, Q-scores, N50, pass/fail counts
\end{itemize}

\subsection*{Quality Score Computation}

Mean quality scores were calculated using probability-space averaging to avoid underestimation from direct Phred score averaging:

\begin{equation}
\bar{Q} = -10 \cdot \log_{10}\left(\frac{1}{n}\sum_{i=1}^{n} 10^{-Q_i/10}\right)
\end{equation}

where $Q_i$ represents individual read quality scores and $n$ is the total read count.

\subsection*{N50 Calculation}

N50 values were computed as the read length at which 50\% of total sequenced bases are contained in reads of equal or greater length:

\begin{equation}
\text{N50} = L_k \text{ where } \sum_{i=1}^{k} L_i \geq \frac{1}{2}\sum_{j=1}^{n} L_j
\end{equation}

with reads sorted by length in descending order ($L_1 \geq L_2 \geq ... \geq L_n$).

\subsection*{Validation and Enrichment}

Registry entries underwent multi-stage validation:

\begin{enumerate}
    \item \textbf{Automated validation}: Schema compliance, value range checks, cross-field consistency
    \item \textbf{Pattern-based inference}: Device type from flowcell identifiers, sample category from directory structure
    \item \textbf{Manual review}: Verification of inferred values, resolution of ambiguous entries
\end{enumerate}

Completeness was scored using a weighted system: critical fields (experiment ID, date, chemistry) received 2 points, important fields (basecaller, device) received 1 point, and QC metrics received 1 point each.

\subsection*{Code Availability}

All analysis code, registry management tools, and figure generation scripts are available in the ont-ecosystem repository. The registry uses an event-sourced architecture where all modifications are logged with timestamps, enabling full provenance reconstruction.

% ============================================================================
% DATA RECORDS
% ============================================================================
\section*{Data Records}

The registry is deposited in the GitHub repository\cite{ont_ecosystem_2025} and available in three formats:

\subsection*{Primary Format: YAML}

The authoritative registry is maintained in YAML format (\texttt{experiments.yaml}) with the following structure for each entry:

\begin{verbatim}
exp-a1b2c3d4:
  name: "Experiment Name"
  date: "2024-01-15"
  sample:
    category: plasmid
    name: "pUC19"
  chemistry:
    flowcell_type: FLO-MIN114
    kit: SQK-LSK114
    version: R10.4.1
  basecalling:
    software: dorado
    model: hac
  device:
    type: MinION_Mk1D
  qc:
    total_reads: 500000
    mean_qscore: 14.2
    n50: 5200
\end{verbatim}

\subsection*{Export Formats}

\begin{itemize}
    \item \textbf{JSON} (\texttt{experiments.json}): Machine-readable format for programmatic access
    \item \textbf{CSV} (\texttt{experiments.csv}): Flattened tabular format for spreadsheet analysis
\end{itemize}

\subsection*{Registry Statistics}

Table~\ref{tab:summary} summarizes the registry contents. The 165 experiments span August 2020 to December 2025, with 100\% completeness for critical metadata fields.

\begin{table}[htbp]
\centering
\caption{Registry summary statistics}
\label{tab:summary}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Total experiments & 165 \\
Temporal range & Aug 2020 -- Dec 2025 \\
Chemistry: R10.4.1 & 157 (95.2\%) \\
Chemistry: R10.4 & 8 (4.8\%) \\
Basecaller: dorado & 136 (82.4\%) \\
Basecaller: guppy & 14 (8.5\%) \\
Model: hac & 148 (89.7\%) \\
Model: sup & 12 (7.3\%) \\
Experiments with QC data & 150 (90.9\%) \\
Median Q-score & 14.0 \\
Median N50 & 4,828 bp \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Sample Categories}

Experiments are classified into eight categories (Figure~\ref{fig:overview}A):

\begin{itemize}
    \item \textbf{Plasmid} (n=80, 48.5\%): Laboratory constructs, expression vectors
    \item \textbf{Research} (n=39, 23.6\%): Method development, proof-of-concept studies
    \item \textbf{Human} (n=16, 9.7\%): Human genomic samples
    \item \textbf{Pharmacogenomics} (n=13, 7.9\%): Clinical PGx samples (CYP2D6, CYP2C19)
    \item \textbf{Standard} (n=8, 4.8\%): Reference materials, QC standards
    \item \textbf{Bacterial} (n=5, 3.0\%): Microbial isolates
    \item \textbf{Cell line} (n=2, 1.2\%): Immortalized cell lines
    \item \textbf{Other} (n=2, 1.2\%): Miscellaneous samples
\end{itemize}

% ============================================================================
% TECHNICAL VALIDATION
% ============================================================================
\section*{Technical Validation}

\subsection*{Metadata Completeness}

Registry completeness was assessed across all fields (Table~\ref{tab:completeness}). Critical fields (experiment ID, date, chemistry version, basecaller) achieved 100\% completeness. QC metrics were available for 150 experiments (90.9\%), with 15 experiments pending analysis on the institutional HPC cluster.

\begin{table}[htbp]
\centering
\caption{Metadata completeness by field category}
\label{tab:completeness}
\begin{tabular}{llr}
\toprule
\textbf{Category} & \textbf{Field} & \textbf{Completeness} \\
\midrule
Experiment & id, name, date & 100\% \\
Sample & category & 100\% \\
Chemistry & flowcell\_type, version & 100\% \\
Basecalling & software, model & 100\% \\
Device & type & 100\% \\
QC & mean\_qscore, n50 & 90.9\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection*{Quality Metric Distributions}

Quality scores follow expected distributions for R10.4.1 chemistry with high-accuracy basecalling (Figure~\ref{fig:qc}). The median Q-score of 14.0 corresponds to approximately 96\% per-base accuracy, consistent with published benchmarks for the hac model\cite{ont_accuracy_2023}.

N50 distributions show bimodal character reflecting the diversity of sample types: plasmid sequencing typically yields shorter fragments (2--8 kb), while genomic applications produce longer reads (10--50 kb).

\subsection*{Cross-Validation}

Metadata consistency was validated through:

\begin{enumerate}
    \item \textbf{Flowcell-chemistry concordance}: FLO-MIN114 exclusively paired with R10.4.1
    \item \textbf{Temporal consistency}: Dorado adoption correlates with R10.4.1 chemistry timeline
    \item \textbf{QC plausibility}: Q-scores and N50 values within expected ranges for reported chemistry/model combinations
\end{enumerate}

No inconsistencies were identified during validation.

% ============================================================================
% USAGE NOTES
% ============================================================================
\section*{Usage Notes}

\subsection*{Accessing the Registry}

The registry can be accessed programmatically:

\begin{verbatim}
# Python
import yaml
with open('experiments.yaml') as f:
    registry = yaml.safe_load(f)

# Filter by chemistry
r10_exps = [e for e in registry.values()
            if e['chemistry']['version'] == 'R10.4.1']
\end{verbatim}

\subsection*{Integration with Analysis Pipelines}

The registry integrates with the ont-ecosystem toolset for:

\begin{itemize}
    \item Experiment discovery and registration
    \item Provenance-tracked analysis execution
    \item Quality control reporting
    \item Cross-experiment comparisons
\end{itemize}

\subsection*{Extending the Registry}

New experiments can be registered using the provided CLI tools:

\begin{verbatim}
ont_experiments.py discover /path/to/data --register
ont_experiments.py validate exp-id
\end{verbatim}

\subsection*{Limitations}

Users should note:

\begin{enumerate}
    \item The registry represents a single institution's sequencing practices
    \item Sample-level raw data access requires institutional data sharing agreements
    \item QC metrics for 15 HPC-archived experiments are pending computation
\end{enumerate}

% ============================================================================
% CODE AVAILABILITY
% ============================================================================
\section*{Code Availability}

The registry management tools, analysis pipelines, and figure generation scripts are available at \url{https://github.com/Single-Molecule-Sequencing/ont-ecosystem} under the MIT license. The repository includes:

\begin{itemize}
    \item Registry YAML/JSON/CSV exports
    \item Python CLI tools for experiment management
    \item Figure generation scripts (matplotlib)
    \item Documentation and usage examples
\end{itemize}

% ============================================================================
% ACKNOWLEDGEMENTS
% ============================================================================
\section*{Acknowledgements}

We thank the University of Michigan Advanced Research Computing (ARC) for providing computational resources. We acknowledge the ONT Open Data initiative for providing public reference datasets.

% ============================================================================
% AUTHOR CONTRIBUTIONS
% ============================================================================
\section*{Author Contributions}

[Author One]: Conceptualization, Data curation, Formal analysis, Software, Visualization, Writing -- original draft.
[Author Two]: Conceptualization, Investigation, Methodology, Validation, Writing -- review \& editing.
[Author Three]: Supervision, Writing -- review \& editing.

% ============================================================================
% COMPETING INTERESTS
% ============================================================================
\section*{Competing Interests}

The authors declare no competing interests.

% ============================================================================
% REFERENCES
% ============================================================================
\bibliographystyle{naturemag}
\bibliography{references_sdata}

% ============================================================================
% FIGURES
% ============================================================================
\clearpage

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{../fig_registry_overview.pdf}
\caption{\textbf{Registry overview.} \textbf{(A)} Sample category distribution. \textbf{(B)} Chemistry version adoption. \textbf{(C)} Device type breakdown. \textbf{(D)} Basecalling model usage. \textbf{(E)} Basecaller software distribution. \textbf{(F)} QC metrics summary.}
\label{fig:overview}
\end{figure}

\clearpage

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{../fig_qc_distributions.pdf}
\caption{\textbf{Quality control metric distributions.} \textbf{(A)} Q-score histogram showing median of 14.0. \textbf{(B)} N50 distribution with median of 4,828 bp. \textbf{(C)} Q-score versus N50 scatter plot colored by sample category.}
\label{fig:qc}
\end{figure}

\clearpage

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{../fig_temporal_analysis.pdf}
\caption{\textbf{Temporal trends.} \textbf{(A)} Cumulative experiment count over time. \textbf{(B)} Monthly experiment distribution. \textbf{(C)} Chemistry version adoption timeline. \textbf{(D)} Sample category evolution.}
\label{fig:temporal}
\end{figure}

\end{document}
